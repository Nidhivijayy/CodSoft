# -*- coding: utf-8 -*-
"""codesoft_A2_Task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K015wwgfBEtb4Cz5RRWJbXwJN1KUiZc5
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv('/content/IMDb_Movies_India.csv', encoding='ISO-8859-1')

df['Genre'] = LabelEncoder().fit_transform(df['Genre'])
df['Director'] = LabelEncoder().fit_transform(df['Director'])

def count_actors(actor_names):
    if pd.isna(actor_names):
        return 0
    return len(actor_names.split(','))

df['Num_Actors'] = df['Actor 1'].apply(count_actors)

X = df[['Genre', 'Director', 'Num_Actors']]
y = df['Rating']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

missing_rows = X_train[X_train.isna().any(axis=1) | y_train.isna()]
X_train = X_train.drop(missing_rows.index)
y_train = y_train.drop(missing_rows.index)

model = DecisionTreeRegressor(random_state=42)

model.fit(X_train, y_train)

missing_rows = X_test[X_test.isna().any(axis=1) | y_test.isna()]
X_test = X_test.drop(missing_rows.index)
y_test = y_test.drop(missing_rows.index)

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared (R2) Score: {r2}')

feature_importance = model.feature_importances_
feature_names = X.columns

for feature, importance in zip(feature_names, feature_importance):
    print(f'{feature}: {importance}')

new_data = pd.DataFrame({'Genre': [0], 'Director': [1], 'Num_Actors': [4]})  # Example new data
predicted_rating = model.predict(new_data)
print(f'Predicted Rating for New Movie: {predicted_rating[0]}')

plt.scatter(y_test, y_pred)
plt.xlabel('Actual Ratings')
plt.ylabel('Predicted Ratings')
plt.title('Actual vs. Predicted Ratings')
plt.show()

param_grid = {'max_depth': [None, 5, 10, 15], 'min_samples_split': [2, 5, 10, 20]}
grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

best_model.fit(X_train, y_train)
y_pred_best = best_model.predict(X_test)
mse_best = mean_squared_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)

print(f'Best Model Mean Squared Error: {mse_best}')
print(f'Best Model R-squared (R2) Score: {r2_best}')

from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

model_rf = RandomForestRegressor(random_state=42)
model_rf.fit(X_train, y_train)

model_gb = GradientBoostingRegressor(random_state=42)
model_gb.fit(X_train, y_train)

y_pred_rf = model_rf.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

y_pred_gb = model_gb.predict(X_test)
mse_gb = mean_squared_error(y_test, y_pred_gb)
r2_gb = r2_score(y_test, y_pred_gb)

print("\nRandom Forest Model:")
print(f'Mean Squared Error: {mse_rf}')
print(f'R-squared (R2) Score: {r2_rf}')

print("\nGradient Boosting Model:")
print(f'Mean Squared Error: {mse_gb}')
print(f'R-squared (R2) Score: {r2_gb}')

param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10, 15], 'min_samples_split': [2, 5, 10, 20]}
grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring='neg_mean_squared_error')
grid_search_rf.fit(X_train, y_train)
best_model_rf = grid_search_rf.best_estimator_

best_model_rf.fit(X_train, y_train)
y_pred_best_rf = best_model_rf.predict(X_test)
mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)
r2_best_rf = r2_score(y_test, y_pred_best_rf)

print("\nBest Random Forest Model After Fine-Tuning:")
print(f'Mean Squared Error: {mse_best_rf}')
print(f'R-squared (R2) Score: {r2_best_rf}')